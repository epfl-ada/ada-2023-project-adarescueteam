{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Project Milestone P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Import libraries and set paths </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unidecode as ud\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocessing_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the global variables for the paths to the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your data directory:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fulci\\\\git\\\\ada_23\\\\ada-2023-project-adarescueteam\\\\code\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add your data folder into the 'code' folder, make sure it is in the .gitignore file\n",
    "\n",
    "CODE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(CODE_DIR, 'data')\n",
    "\n",
    "print('your data directory:')\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for BeerAdvocate data\n",
    "DATA_BeerAdvocate = os.path.join(DATA_DIR, \"BeerAdvocate.tar\")\n",
    "\n",
    "# set path for RateBeer data\n",
    "DATA_RateBeer = os.path.join(DATA_DIR, \"RateBeer.tar\")\n",
    "\n",
    "# set path for MatchedBeer data\n",
    "DATA_MatchedBeers = os.path.join(DATA_DIR, \"matched_beer_data.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Load cleaned data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaterBeer (RB) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beers, breweries, users csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the BeerAdvocate files\n",
    "BA_beers = pd.read_csv(os.path.join(DATA_BeerAdvocate, \"beers.csv\"))\n",
    "BA_breweries = pd.read_csv(os.path.join(DATA_BeerAdvocate, \"breweries.csv\"))\n",
    "BA_users = pd.read_csv(os.path.join(DATA_BeerAdvocate, \"users.csv\"), \n",
    "                       converters={\"joined\": convert_timestamp})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratings pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read RB_ratings from pickle file\n",
    "with open(os.path.join(DATA_RateBeer, \"RB_ratings.pkl\"), 'rb') as f:\n",
    "    RB_ratings = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeerAdvocate (BA) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beers, breweries, users csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the RateBeer files\n",
    "RB_beers = pd.read_csv(os.path.join(DATA_RateBeer, \"beers.csv\"))\n",
    "RB_breweries = pd.read_csv(os.path.join(DATA_RateBeer, \"breweries.csv\"))\n",
    "RB_users = pd.read_csv(os.path.join(DATA_RateBeer, \"users.csv\"),\n",
    "                       converters={\"joined\": convert_timestamp})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratings pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read BA_ratings from pickle file\n",
    "with open(os.path.join(DATA_BeerAdvocate, \"BA_ratings.pkl\"), 'rb') as f:\n",
    "    BA_ratings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glutenfree (gf) Beer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3770, 18), (2397, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the glutenfree beers\n",
    "rb_gf_ratings=pd.read_csv(os.path.join(DATA_RateBeer, 'rb_gf_ratings.csv'), low_memory=False, encoding='utf-8')\n",
    "ba_gf_ratings=pd.read_csv(os.path.join(DATA_BeerAdvocate, 'ba_gf_ratings.csv'), low_memory=False, encoding='utf-8')\n",
    "rb_gf_ratings.shape, ba_gf_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6167, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two datasets\n",
    "frames = [rb_gf_ratings, ba_gf_ratings]\n",
    "rb_ba_gf_ratings = pd.concat(frames)\n",
    "rb_ba_gf_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_ba_gf_ratings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Filter data for matching </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Merge the RB and BA dataframe after filtering </span>\n",
    "\n",
    "shrink down the datasets before matching non-glutenfree reviews with glutenfree reviews, takes too long to work else\n",
    "\n",
    "and not to forget: eliminate duplicates, because most likely as we dont consider the Matched_beer dataset => done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add review columns to RB_ratings before joining them. all entries have reviews\n",
    "RB_ratings['review']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15515106, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [BA_ratings, RB_ratings]\n",
    "RB_BA_ratings = pd.concat(frames)\n",
    "RB_BA_ratings.shape\n",
    "# takes 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB_BA_ratings.duplicated().sum()\n",
    "# takes 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_BA_ratings = RB_BA_ratings[~RB_BA_ratings.duplicated()]\n",
    "# takes 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB_BA_ratings.duplicated().sum()\n",
    "# takes again 35s -> this is why we need to shrink down the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Temporal analyis</span>\n",
    "\n",
    "-> can fill with a lot of P2_AfterMilestone from the 'fix_nlp_and_text-formats' branch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Language processing</span>\n",
    "\n",
    "suggest that we write functions / pipeline in an outside script and in here just leave the important things\n",
    "\n",
    "-> can fill with a lot of P2_AfterMilestone from the 'fix_nlp_and_text-formats' branch \n",
    "\n",
    "-> dont forget to do the analysis on the whole rb_ba_gf dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> can fill with a lot of P2_AfterMilestone from the 'fix_nlp_and_text-formats' branch , need to see what to keep though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjective and adverbs extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: lightgreen;\">correlation of the reviews with the ratings</span> TBD\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
