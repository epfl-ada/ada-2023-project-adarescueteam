{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Project Milestone P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Import libraries and set paths </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unidecode as ud\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocessing_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the global variables for the paths to the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your data directory:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fulci\\\\git\\\\ada_23\\\\ada-2023-project-adarescueteam\\\\code\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add your data folder into the 'code' folder, make sure it is in the .gitignore file\n",
    "\n",
    "CODE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(CODE_DIR, 'data')\n",
    "\n",
    "print('your data directory:')\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for BeerAdvocate data\n",
    "DATA_BeerAdvocate = os.path.join(DATA_DIR, \"BeerAdvocate.tar\")\n",
    "\n",
    "# set path for RateBeer data\n",
    "DATA_RateBeer = os.path.join(DATA_DIR, \"RateBeer.tar\")\n",
    "\n",
    "# set path for MatchedBeer data\n",
    "DATA_MatchedBeers = os.path.join(DATA_DIR, \"matched_beer_data.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Load cleaned data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaterBeer (RB) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beers, breweries, users csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the BeerAdvocate files\n",
    "BA_beers = pd.read_csv(os.path.join(DATA_BeerAdvocate, \"beers.csv\"))\n",
    "BA_breweries = pd.read_csv(os.path.join(DATA_BeerAdvocate, \"breweries.csv\"))\n",
    "BA_users = pd.read_csv(os.path.join(DATA_BeerAdvocate, \"users.csv\"), \n",
    "                       converters={\"joined\": convert_timestamp})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratings pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read RB_ratings from pickle file\n",
    "with open(os.path.join(DATA_RateBeer, \"RB_ratings.pkl\"), 'rb') as f:\n",
    "    RB_ratings = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeerAdvocate (BA) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beers, breweries, users csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the RateBeer files\n",
    "RB_beers = pd.read_csv(os.path.join(DATA_RateBeer, \"beers.csv\"))\n",
    "RB_breweries = pd.read_csv(os.path.join(DATA_RateBeer, \"breweries.csv\"))\n",
    "RB_users = pd.read_csv(os.path.join(DATA_RateBeer, \"users.csv\"),\n",
    "                       converters={\"joined\": convert_timestamp})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratings pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read BA_ratings from pickle file\n",
    "with open(os.path.join(DATA_BeerAdvocate, \"BA_ratings.pkl\"), 'rb') as f:\n",
    "    BA_ratings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glutenfree (gf) Beer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3770, 18), (2397, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the glutenfree beers\n",
    "rb_gf_ratings=pd.read_csv(os.path.join(DATA_RateBeer, 'rb_gf_ratings.csv'), low_memory=False, encoding='utf-8')\n",
    "ba_gf_ratings=pd.read_csv(os.path.join(DATA_BeerAdvocate, 'ba_gf_ratings.csv'), low_memory=False, encoding='utf-8')\n",
    "rb_gf_ratings.shape, ba_gf_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the review columns to the rb_gf_ratings\n",
    "rb_gf_ratings['review'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6167, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two datasets\n",
    "gf_ratings = pd.concat([rb_gf_ratings, ba_gf_ratings])\n",
    "gf_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "gf_ratings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Filter data for matching </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we want to match the glutenfree (gf) beers by style with the conventional beers. For this we can remove all the style in the BA or RB dataset, which is not represented in the gf beer dataset.\n",
    "\n",
    "Following this, we merge the two _style datasets and check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only beer-types present in gluten-free beers\n",
    "\n",
    "gf_beers=gf_ratings['beer_name'].unique()\n",
    "\n",
    "for i in range(len(gf_beers)): #Somehow there is a space at beginning of beer_names\n",
    "    gf_beers[i]=gf_beers[i][1:]\n",
    "\n",
    "BA_gf_beertypes = BA_beers[BA_beers['beer_name'].isin(gf_beers)]['style'].unique()\n",
    "RB_gf_beertypes = RB_beers[RB_beers['beer_name'].isin(gf_beers)]['style'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_beertypes = np.concatenate((BA_gf_beertypes,RB_gf_beertypes))\n",
    "gf_beertypes=pd.DataFrame(gf_beertypes,columns=['style'])\n",
    "gf_beertypes=gf_beertypes['style'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent only the styles in the full dataset that are also represented in the glutenfree dataset\n",
    "# Here we do the comparison by first extracting the beer_id with the beer style from the datasets, as there is issues comparing directly the array gf_beertypes\n",
    "\n",
    "# for BeerAdvocate \n",
    "BA_beers[BA_beers['style'].isin(gf_beertypes)]  # 169793 rows\n",
    "BA_beerID_style = BA_beers[BA_beers['style'].isin(gf_beertypes)][['beer_id', 'style']]\n",
    "BA_ratings_style = BA_ratings[BA_ratings['beer_id'].isin(BA_beerID_style['beer_id'])]\n",
    "\n",
    "# and the same for Ratebeer\n",
    "RB_beers[RB_beers['style'].isin(gf_beertypes)]\n",
    "RB_beerID_style = RB_beers[RB_beers['style'].isin(gf_beertypes)][['beer_id', 'style']]\n",
    "RB_ratings_style = RB_ratings[RB_ratings['beer_id'].isin(RB_beerID_style['beer_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fulci\\AppData\\Local\\Temp\\ipykernel_9772\\130779583.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  RB_ratings_style['review'] = True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9371934, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge this two dataframes\n",
    "    # beforehands, we add a review column to avoid nan conflicts later\n",
    "RB_ratings_style['review'] = True\n",
    "ratings_style = pd.concat([BA_ratings_style, RB_ratings_style])\n",
    "ratings_style.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "ratings_style.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all duplicates and check again\n",
    "ratings_style = ratings_style[~ratings_style.duplicated(keep='first')]\n",
    "ratings_style.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that the glutenfree beers are not contained in the full data, especially because not subtracting the gf data would produce duplicates in the analysis and thus unwanted perfect matchings between the same samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Régab</td>\n",
       "      <td>142544</td>\n",
       "      <td>Societe des Brasseries du Gabon (SOBRAGA)</td>\n",
       "      <td>37262</td>\n",
       "      <td>Euro Pale Lager</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2015-08-20 10:00:00</td>\n",
       "      <td>nmann08</td>\n",
       "      <td>nmann08.184925</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>From a bottle, pours a piss yellow color with...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barelegs Brew</td>\n",
       "      <td>19590</td>\n",
       "      <td>Strangford Lough Brewing Company Ltd</td>\n",
       "      <td>10093</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-02-20 11:00:00</td>\n",
       "      <td>StJamesGate</td>\n",
       "      <td>stjamesgate.163714</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Pours pale copper with a thin head that quick...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barelegs Brew</td>\n",
       "      <td>19590</td>\n",
       "      <td>Strangford Lough Brewing Company Ltd</td>\n",
       "      <td>10093</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2006-03-13 11:00:00</td>\n",
       "      <td>mdagnew</td>\n",
       "      <td>mdagnew.19527</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.73</td>\n",
       "      <td>500ml Bottle bought from The Vintage, Antrim....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barelegs Brew</td>\n",
       "      <td>19590</td>\n",
       "      <td>Strangford Lough Brewing Company Ltd</td>\n",
       "      <td>10093</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2004-12-01 11:00:00</td>\n",
       "      <td>helloloser12345</td>\n",
       "      <td>helloloser12345.10867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.98</td>\n",
       "      <td>Serving: 500ml brown bottlePour: Good head wi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barelegs Brew</td>\n",
       "      <td>19590</td>\n",
       "      <td>Strangford Lough Brewing Company Ltd</td>\n",
       "      <td>10093</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2004-08-30 10:00:00</td>\n",
       "      <td>cypressbob</td>\n",
       "      <td>cypressbob.3708</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>500ml bottlePours with a light, slightly hazy...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371917</th>\n",
       "      <td>Svejk Blonde</td>\n",
       "      <td>220897</td>\n",
       "      <td>Svejk Beer Garden</td>\n",
       "      <td>17155</td>\n",
       "      <td>Pale Lager</td>\n",
       "      <td>nan</td>\n",
       "      <td>2014-09-18 10:00:00</td>\n",
       "      <td>Travlr</td>\n",
       "      <td>83882</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Draft at the source. Clear golden color, fluf...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371918</th>\n",
       "      <td>Svejk Blonde</td>\n",
       "      <td>220897</td>\n",
       "      <td>Svejk Beer Garden</td>\n",
       "      <td>17155</td>\n",
       "      <td>Pale Lager</td>\n",
       "      <td>nan</td>\n",
       "      <td>2013-12-01 11:00:00</td>\n",
       "      <td>TBone</td>\n",
       "      <td>10233</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Tap @brewpub, TiraneClear golden color, good ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371919</th>\n",
       "      <td>Svejk Dark</td>\n",
       "      <td>220898</td>\n",
       "      <td>Svejk Beer Garden</td>\n",
       "      <td>17155</td>\n",
       "      <td>Dunkel/Tmavý</td>\n",
       "      <td>nan</td>\n",
       "      <td>2014-11-04 11:00:00</td>\n",
       "      <td>Rob_D_UK</td>\n",
       "      <td>257161</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2.30</td>\n",
       "      <td>In their beer garden after a walking tour aro...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371920</th>\n",
       "      <td>Svejk Dark</td>\n",
       "      <td>220898</td>\n",
       "      <td>Svejk Beer Garden</td>\n",
       "      <td>17155</td>\n",
       "      <td>Dunkel/Tmavý</td>\n",
       "      <td>nan</td>\n",
       "      <td>2014-09-16 10:00:00</td>\n",
       "      <td>Travlr</td>\n",
       "      <td>83882</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.90</td>\n",
       "      <td>Draft at the source. Hazy maroon color, tan h...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371921</th>\n",
       "      <td>Svejk Dark</td>\n",
       "      <td>220898</td>\n",
       "      <td>Svejk Beer Garden</td>\n",
       "      <td>17155</td>\n",
       "      <td>Dunkel/Tmavý</td>\n",
       "      <td>nan</td>\n",
       "      <td>2013-12-01 11:00:00</td>\n",
       "      <td>TBone</td>\n",
       "      <td>10233</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.20</td>\n",
       "      <td>Tap @brewpub, TiraneDark brown color, nice cr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9368152 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              beer_name  beer_id                                brewery_name  \\\n",
       "0                 Régab   142544   Societe des Brasseries du Gabon (SOBRAGA)   \n",
       "1         Barelegs Brew    19590        Strangford Lough Brewing Company Ltd   \n",
       "2         Barelegs Brew    19590        Strangford Lough Brewing Company Ltd   \n",
       "3         Barelegs Brew    19590        Strangford Lough Brewing Company Ltd   \n",
       "4         Barelegs Brew    19590        Strangford Lough Brewing Company Ltd   \n",
       "...                 ...      ...                                         ...   \n",
       "9371917    Svejk Blonde   220897                           Svejk Beer Garden   \n",
       "9371918    Svejk Blonde   220897                           Svejk Beer Garden   \n",
       "9371919      Svejk Dark   220898                           Svejk Beer Garden   \n",
       "9371920      Svejk Dark   220898                           Svejk Beer Garden   \n",
       "9371921      Svejk Dark   220898                           Svejk Beer Garden   \n",
       "\n",
       "         brewery_id              style   abv                 date  \\\n",
       "0             37262    Euro Pale Lager   4.5  2015-08-20 10:00:00   \n",
       "1             10093   English Pale Ale   4.5  2009-02-20 11:00:00   \n",
       "2             10093   English Pale Ale   4.5  2006-03-13 11:00:00   \n",
       "3             10093   English Pale Ale   4.5  2004-12-01 11:00:00   \n",
       "4             10093   English Pale Ale   4.5  2004-08-30 10:00:00   \n",
       "...             ...                ...   ...                  ...   \n",
       "9371917       17155         Pale Lager   nan  2014-09-18 10:00:00   \n",
       "9371918       17155         Pale Lager   nan  2013-12-01 11:00:00   \n",
       "9371919       17155       Dunkel/Tmavý   nan  2014-11-04 11:00:00   \n",
       "9371920       17155       Dunkel/Tmavý   nan  2014-09-16 10:00:00   \n",
       "9371921       17155       Dunkel/Tmavý   nan  2013-12-01 11:00:00   \n",
       "\n",
       "                user_name                 user_id appearance  aroma palate  \\\n",
       "0                 nmann08          nmann08.184925       3.25   2.75   3.25   \n",
       "1             StJamesGate      stjamesgate.163714        3.0    3.5    3.5   \n",
       "2                 mdagnew           mdagnew.19527        4.0    3.5    3.5   \n",
       "3         helloloser12345   helloloser12345.10867        4.0    3.5    4.0   \n",
       "4              cypressbob         cypressbob.3708        4.0    4.0    4.0   \n",
       "...                   ...                     ...        ...    ...    ...   \n",
       "9371917            Travlr                   83882          3      6      2   \n",
       "9371918             TBone                   10233          2      5      2   \n",
       "9371919          Rob_D_UK                  257161          3      4      2   \n",
       "9371920            Travlr                   83882          3      5      1   \n",
       "9371921             TBone                   10233          4      4      2   \n",
       "\n",
       "         taste overall  rating  \\\n",
       "0         2.75     3.0    2.88   \n",
       "1          4.0     3.5    3.67   \n",
       "2          4.0     3.5    3.73   \n",
       "3          4.0     4.5    3.98   \n",
       "4          4.0     4.0    4.00   \n",
       "...        ...     ...     ...   \n",
       "9371917      5      10    2.60   \n",
       "9371918      6      10    2.50   \n",
       "9371919      5       9    2.30   \n",
       "9371920      4       6    1.90   \n",
       "9371921      4       8    2.20   \n",
       "\n",
       "                                                      text review  \n",
       "0         From a bottle, pours a piss yellow color with...   True  \n",
       "1         Pours pale copper with a thin head that quick...   True  \n",
       "2         500ml Bottle bought from The Vintage, Antrim....   True  \n",
       "3         Serving: 500ml brown bottlePour: Good head wi...   True  \n",
       "4         500ml bottlePours with a light, slightly hazy...   True  \n",
       "...                                                    ...    ...  \n",
       "9371917   Draft at the source. Clear golden color, fluf...   True  \n",
       "9371918   Tap @brewpub, TiraneClear golden color, good ...   True  \n",
       "9371919   In their beer garden after a walking tour aro...   True  \n",
       "9371920   Draft at the source. Hazy maroon color, tan h...   True  \n",
       "9371921   Tap @brewpub, TiraneDark brown color, nice cr...   True  \n",
       "\n",
       "[9368152 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dfs and only keep the rows that are present in ratings_style but not in gf_ratings\n",
    "merged_ratings = pd.merge(ratings_style, gf_ratings, indicator=True, how='outer')\n",
    "ratings_style = merged_ratings[merged_ratings['_merge'] == 'left_only'].drop(columns=['_merge', 'location', 'year'])\n",
    "ratings_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prepare the dataset for the third question which looks at the reviews, we filter out the samples that have no review and create **reviews_style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4810208"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ratings_style['review']!=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4557944, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_style = ratings_style[(ratings_style['review'] == True)]\n",
    "reviews_style.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we only want to focus on the reviews that are either english or french, thus we remove all languages that we are not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x21893818350>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pl',\n",
       " 'es',\n",
       " 'pl',\n",
       " 'es',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'es',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'it',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'sv',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'sv',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'no',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'it',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'it',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'da',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'fr',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'fr',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'ru',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'es',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'sv',\n",
       " 'en',\n",
       " 'en',\n",
       " 'es',\n",
       " 'en',\n",
       " 'fr',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'fr',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'fr',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'no',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'de',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'hu',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'pl',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " ...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27180/4557956 [05:26<15:05:51, 83.36it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reviews_style))):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews_style\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m         reviews_languages\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39m_\u001b[38;5;241m.\u001b[39mlanguage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[0;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[0;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataXd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\layers\\concatenate.py:65\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(OutT, data_r), backprop\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     data_a, backprop \u001b[38;5;241m=\u001b[39m \u001b[43m_array_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(OutT, data_a), backprop\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\thinc\\layers\\concatenate.py:73\u001b[0m, in \u001b[0;36m_array_forward\u001b[1;34m(model, X, Ys, callbacks, is_train)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_forward\u001b[39m(\n\u001b[0;32m     70\u001b[0m     model: Model[InT, OutT], X, Ys: List, callbacks, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Array2d, Callable]:\n\u001b[0;32m     72\u001b[0m     widths \u001b[38;5;241m=\u001b[39m [Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m Y \u001b[38;5;129;01min\u001b[39;00m Ys]\n\u001b[1;32m---> 73\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(d_output: Array2d) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InT:\n\u001b[0;32m     76\u001b[0m         dY \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mas_contig(d_output[:, : widths[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fulci\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:370\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reviews_languages = []\n",
    "\n",
    "for row in tqdm(range(len(reviews_style))):\n",
    "    try:\n",
    "        doc = nlp(reviews_style['text'].iloc[row])\n",
    "        reviews_languages.append(doc._.language['language'])\n",
    "    except Exception as e:\n",
    "        reviews_languages.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def process_text(row):\n",
    "    try:\n",
    "        doc = nlp(reviews_style['text'].iloc[row])\n",
    "        return doc._.language['language']\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "reviews_languages = []\n",
    "chunk_size = 10000  # You can adjust this chunk size based on memory constraints\n",
    "chunks_list = list(chunks(range(len(reviews_style)), chunk_size))\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    return [process_text(row) for row in chunk]\n",
    "\n",
    "with Pool(cpu_count() - 1) as p:\n",
    "    results = p.map(process_chunk, chunks_list)\n",
    "\n",
    "for result in results:\n",
    "    reviews_languages.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Merge the RB and BA dataframe after filtering </span>\n",
    "\n",
    "shrink down the datasets before matching non-glutenfree reviews with glutenfree reviews, takes too long to work else\n",
    "\n",
    "and not to forget: eliminate duplicates, because most likely as we dont consider the Matched_beer dataset => done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add review columns to RB_ratings before joining them. all entries have reviews\n",
    "RB_ratings['review']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15515106, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [BA_ratings, RB_ratings]\n",
    "RB_BA_ratings = pd.concat(frames)\n",
    "RB_BA_ratings.shape\n",
    "# takes 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB_BA_ratings.duplicated().sum()\n",
    "# takes 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_BA_ratings = RB_BA_ratings[~RB_BA_ratings.duplicated()]\n",
    "# takes 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB_BA_ratings.duplicated().sum()\n",
    "# takes again 35s -> this is why we need to shrink down the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Temporal analyis</span>\n",
    "\n",
    "-> can fill with a lot of P2_AfterMilestone from the 'fix_nlp_and_text-formats' branch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">Language processing</span>\n",
    "\n",
    "suggest that we write functions / pipeline in an outside script and in here just leave the important things\n",
    "\n",
    "-> can fill with a lot of P2_AfterMilestone from the 'fix_nlp_and_text-formats' branch \n",
    "\n",
    "-> dont forget to do the analysis on the whole rb_ba_gf dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> can fill with a lot of P2_AfterMilestone from the 'fix_nlp_and_text-formats' branch , need to see what to keep though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjective and adverbs extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: lightgreen;\">correlation of the reviews with the ratings</span> TBD\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
